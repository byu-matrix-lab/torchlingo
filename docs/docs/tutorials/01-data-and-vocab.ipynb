{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "109dca82",
   "metadata": {},
   "source": [
    "# Tutorial 1: Data and Vocabulary\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/byu-matrix-lab/torchlingo/blob/main/docs/docs/tutorials/01-data-and-vocab.ipynb)\n",
    "\n",
    "Learn how to load parallel data, build vocabularies, and prepare your data for neural machine translation.\n",
    "\n",
    "**⚡ Running in Google Colab?** Make sure to:\n",
    "1. Go to **Runtime → Change runtime type → GPU** (optional but faster)\n",
    "2. Uncomment and run the `%pip install torchlingo` cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68938889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.1\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "# Install TorchLingo (uncomment in Google Colab)\n",
    "# %pip install torchlingo\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46c2372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Import TorchLingo modules\n",
    "from torchlingo.preprocessing import load_data, parallel_txt_to_dataframe\n",
    "from torchlingo.data_processing import SimpleVocab, NMTDataset\n",
    "from torchlingo.config import Config, get_default_config\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"✓ Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe86196",
   "metadata": {},
   "source": [
    "## Part 1: Loading Data\n",
    "\n",
    "TorchLingo supports multiple data formats. Let's create some sample data and load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f48ced8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data:\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "src",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tgt",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "44587bba-883c-406b-962a-b4edf90726e3",
       "rows": [
        [
         "0",
         "Hello world",
         "Hola mundo"
        ],
        [
         "1",
         "Hello neighbor",
         "Hola vecino"
        ],
        [
         "2",
         "Cruel world",
         "Mundo cruel"
        ],
        [
         "3",
         "How are you today",
         "Cómo estás hoy"
        ],
        [
         "4",
         "Good morning",
         "Buenos días"
        ],
        [
         "5",
         "Thank you very much",
         "Muchas gracias"
        ],
        [
         "6",
         "I love programming",
         "Me encanta programar"
        ],
        [
         "7",
         "The cat is sleeping",
         "El gato está durmiendo"
        ],
        [
         "8",
         "What is your name",
         "Cuál es tu nombre"
        ],
        [
         "9",
         "Nice to meet you",
         "Mucho gusto"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello world</td>\n",
       "      <td>Hola mundo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello neighbor</td>\n",
       "      <td>Hola vecino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cruel world</td>\n",
       "      <td>Mundo cruel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How are you today</td>\n",
       "      <td>Cómo estás hoy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good morning</td>\n",
       "      <td>Buenos días</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thank you very much</td>\n",
       "      <td>Muchas gracias</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I love programming</td>\n",
       "      <td>Me encanta programar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The cat is sleeping</td>\n",
       "      <td>El gato está durmiendo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What is your name</td>\n",
       "      <td>Cuál es tu nombre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Nice to meet you</td>\n",
       "      <td>Mucho gusto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   src                     tgt\n",
       "0          Hello world              Hola mundo\n",
       "1       Hello neighbor             Hola vecino\n",
       "2          Cruel world             Mundo cruel\n",
       "3    How are you today          Cómo estás hoy\n",
       "4         Good morning             Buenos días\n",
       "5  Thank you very much          Muchas gracias\n",
       "6   I love programming    Me encanta programar\n",
       "7  The cat is sleeping  El gato está durmiendo\n",
       "8    What is your name       Cuál es tu nombre\n",
       "9     Nice to meet you             Mucho gusto"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create sample parallel data\n",
    "sample_data = {\n",
    "    \"src\": [\n",
    "        \"Hello world\",\n",
    "        \"Hello neighbor\",\n",
    "        \"Cruel world\",\n",
    "        \"How are you today\",\n",
    "        \"Good morning\",\n",
    "        \"Thank you very much\",\n",
    "        \"I love programming\",\n",
    "        \"The cat is sleeping\",\n",
    "        \"What is your name\",\n",
    "        \"Nice to meet you\",\n",
    "    ],\n",
    "    \"tgt\": [\n",
    "        \"Hola mundo\",\n",
    "        \"Hola vecino\",\n",
    "        \"Mundo cruel\",\n",
    "        \"Cómo estás hoy\",\n",
    "        \"Buenos días\",\n",
    "        \"Muchas gracias\",\n",
    "        \"Me encanta programar\",\n",
    "        \"El gato está durmiendo\",\n",
    "        \"Cuál es tu nombre\",\n",
    "        \"Mucho gusto\",\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(sample_data)\n",
    "print(\"Sample data:\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fdce53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data/sample_train.tsv\n"
     ]
    }
   ],
   "source": [
    "# Save as TSV (tab-separated values)\n",
    "data_dir = Path(\"data\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "data_path = data_dir / \"sample_train.tsv\"\n",
    "df.to_csv(data_path, sep=\"\\t\", index=False)\n",
    "print(f\"Saved to {data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4613e9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 rows\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "src",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "tgt",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "8409d670-df0b-4317-8819-b14d34915abc",
       "rows": [
        [
         "0",
         "Hello world",
         "Hola mundo"
        ],
        [
         "1",
         "Hello neighbor",
         "Hola vecino"
        ],
        [
         "2",
         "Cruel world",
         "Mundo cruel"
        ],
        [
         "3",
         "How are you today",
         "Cómo estás hoy"
        ],
        [
         "4",
         "Good morning",
         "Buenos días"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello world</td>\n",
       "      <td>Hola mundo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hello neighbor</td>\n",
       "      <td>Hola vecino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cruel world</td>\n",
       "      <td>Mundo cruel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How are you today</td>\n",
       "      <td>Cómo estás hoy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good morning</td>\n",
       "      <td>Buenos días</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 src             tgt\n",
       "0        Hello world      Hola mundo\n",
       "1     Hello neighbor     Hola vecino\n",
       "2        Cruel world     Mundo cruel\n",
       "3  How are you today  Cómo estás hoy\n",
       "4       Good morning     Buenos días"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load it back\n",
    "loaded_df = load_data(data_path)\n",
    "print(f\"Loaded {len(loaded_df)} rows\")\n",
    "loaded_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703e6a6a",
   "metadata": {},
   "source": [
    "## Part 2: Building Vocabularies\n",
    "\n",
    "Neural networks work with numbers, not text. A vocabulary maps words to indices and back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331a489b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 8\n",
      "\n",
      "Token to index mapping:\n",
      "  '<pad>' → 0\n",
      "  '<unk>' → 1\n",
      "  '<sos>' → 2\n",
      "  '<eos>' → 3\n",
      "  'Hello' → 4\n",
      "  'world' → 5\n",
      "  'you' → 6\n",
      "  'is' → 7\n"
     ]
    }
   ],
   "source": [
    "# Create a vocabulary\n",
    "vocab = SimpleVocab()\n",
    "\n",
    "# Build from sentences\n",
    "vocab.build_vocab(df[\"src\"].tolist())\n",
    "\n",
    "print(f\"Vocabulary size: {len(vocab)}\")\n",
    "print(f\"\\nToken to index mapping:\")\n",
    "for token, idx in list(vocab.token2idx.items())[:10]:\n",
    "    print(f\"  '{token}' → {idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b7dcf8",
   "metadata": {},
   "source": [
    "### Special Tokens\n",
    "\n",
    "Notice the first four tokens are special:\n",
    "\n",
    "| Token | Index | Purpose |\n",
    "|-------|-------|------|\n",
    "| `<pad>` | 0 | Padding for batching |\n",
    "| `<unk>` | 1 | Unknown words |\n",
    "| `<sos>` | 2 | Start of sequence |\n",
    "| `<eos>` | 3 | End of sequence |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb20dec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 'Hello world'\n",
      "Encoded:  [2, 4, 5, 3]\n",
      "Meaning:  [SOS, 'Hello', 'world', EOS]\n"
     ]
    }
   ],
   "source": [
    "# Encode a sentence\n",
    "sentence = \"Hello world\"\n",
    "indices = vocab.encode(sentence, add_special_tokens=True)\n",
    "\n",
    "print(f\"Original: '{sentence}'\")\n",
    "print(f\"Encoded:  {indices}\")\n",
    "print(f\"Meaning:  [SOS, 'Hello', 'world', EOS]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "847a0869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded: 'Hello world'\n",
      "With special tokens: '<sos> Hello world <eos>'\n"
     ]
    }
   ],
   "source": [
    "# Decode back to text\n",
    "decoded = vocab.decode(indices, skip_special_tokens=True)\n",
    "print(f\"Decoded: '{decoded}'\")\n",
    "\n",
    "# With special tokens\n",
    "decoded_with_special = vocab.decode(indices, skip_special_tokens=False)\n",
    "print(f\"With special tokens: '{decoded_with_special}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b45d46",
   "metadata": {},
   "source": [
    "### Handling Unknown Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7f16dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 'Hello universe'\n",
      "Encoded:  [2, 4, 1, 3]\n",
      "With special tokens: '<sos> Hello <unk> <eos>'\n"
     ]
    }
   ],
   "source": [
    "# What happens with words not in our vocabulary?\n",
    "unknown_sentence = \"Hello universe\"\n",
    "indices = vocab.encode(unknown_sentence, add_special_tokens=True)\n",
    "\n",
    "print(f\"Original: '{unknown_sentence}'\")\n",
    "print(f\"Encoded:  {indices}\")\n",
    "# With special tokens\n",
    "decoded_with_special = vocab.decode(indices, skip_special_tokens=False)\n",
    "print(f\"With special tokens: '{decoded_with_special}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b34f7f",
   "metadata": {},
   "source": [
    "## Part 3: Creating Datasets\n",
    "\n",
    "The `NMTDataset` class combines data loading and vocabulary building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3674b173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 10 samples\n",
      "Source vocab: 8 tokens\n",
      "Target vocab: 5 tokens\n"
     ]
    }
   ],
   "source": [
    "# Create dataset (vocabularies built automatically)\n",
    "dataset = NMTDataset(data_path)\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)} samples\")\n",
    "print(f\"Source vocab: {len(dataset.src_vocab)} tokens\")\n",
    "print(f\"Target vocab: {len(dataset.tgt_vocab)} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc8e6410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0:\n",
      "  Source sentence: 'Hello world'\n",
      "  Source tensor:   [2, 4, 5, 3]\n",
      "  Target sentence: 'Hola mundo'\n",
      "  Target tensor:   [2, 4, 1, 3]\n"
     ]
    }
   ],
   "source": [
    "# Access a sample\n",
    "src_tensor, tgt_tensor = dataset[0]\n",
    "\n",
    "print(f\"Sample 0:\")\n",
    "print(f\"  Source sentence: '{dataset.src_sentences[0]}'\")\n",
    "print(f\"  Source tensor:   {src_tensor.tolist()}\")\n",
    "print(f\"  Target sentence: '{dataset.tgt_sentences[0]}'\")\n",
    "print(f\"  Target tensor:   {tgt_tensor.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39bda9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source decoded: '<sos> Hello world <eos>'\n",
      "Target decoded: '<sos> Hola <unk> <eos>'\n"
     ]
    }
   ],
   "source": [
    "# Decode to verify\n",
    "src_decoded = dataset.src_vocab.decode(src_tensor.tolist(), skip_special_tokens=False)\n",
    "tgt_decoded = dataset.tgt_vocab.decode(tgt_tensor.tolist(), skip_special_tokens=False)\n",
    "\n",
    "print(f\"Source decoded: '{src_decoded}'\")\n",
    "print(f\"Target decoded: '{tgt_decoded}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301e0be8",
   "metadata": {},
   "source": [
    "## Part 4: Batching\n",
    "\n",
    "Training requires batching multiple samples together. Let's see how padding works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a6327f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shapes:\n",
      "  Source: torch.Size([4, 6])  (batch_size, max_src_len)\n",
      "  Target: torch.Size([4, 6])  (batch_size, max_tgt_len)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchlingo.data_processing import collate_fn\n",
    "\n",
    "# Create a data loader\n",
    "loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "# Get one batch\n",
    "src_batch, tgt_batch = next(iter(loader))\n",
    "\n",
    "print(f\"Batch shapes:\")\n",
    "print(f\"  Source: {src_batch.shape}  (batch_size, max_src_len)\")\n",
    "print(f\"  Target: {tgt_batch.shape}  (batch_size, max_tgt_len)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44887c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source batch (notice padding with 0s):\n",
      "  Sample 0: [2, 1, 7, 1, 1, 3]\n",
      "  Sample 1: [2, 1, 1, 7, 1, 3]\n",
      "  Sample 2: [2, 1, 1, 1, 6, 3]\n",
      "  Sample 3: [2, 1, 1, 1, 3, 0]\n"
     ]
    }
   ],
   "source": [
    "# Inspect the batch\n",
    "print(\"Source batch (notice padding with 0s):\")\n",
    "for i, seq in enumerate(src_batch):\n",
    "    print(f\"  Sample {i}: {seq.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cecd417",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You've learned:\n",
    "\n",
    "1. **Loading data**: Use `load_data()` for TSV, CSV, JSON, Parquet\n",
    "2. **Vocabularies**: Map words ↔ indices with special tokens\n",
    "3. **Datasets**: `NMTDataset` handles encoding automatically\n",
    "4. **Batching**: `collate_fn` pads sequences for batching\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Continue to [Tutorial 2: Training a Tiny Model](02-train-tiny-model.ipynb) to build and train your first translation model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
